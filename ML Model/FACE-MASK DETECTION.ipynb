{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(file_path):\n",
    "  size = os.path.getsize(file_path)\n",
    "  return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes(size, unit=None):\n",
    "  if unit == \"KB\":\n",
    "    return print('File size: ' + str(round(size/1024,3)) + ' kilobytes')\n",
    "  elif unit == \"MB\":\n",
    "    return print('File size: ' + str(round(size/(1024*1024),3)) + ' Megabytes')\n",
    "  else:\n",
    "    return print('File size: ' + str(size) + ' bytes') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "from tensorflow.keras.layers import AveragePooling2D,Flatten,Dropout,Dense,Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# VIDEO PLAYBACK\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "from playsound import playsound\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "from plyer import notification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 0.0001\n",
    "EPOCHS = 30\n",
    "BS = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=r'C:\\Users\\shubh\\anaconda3\\envs\\PROJECT\\FACEMASK DETECTION\\dataset'\n",
    "imagePaths = list(paths.list_images(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    \n",
    "    image = load_img(imagePath, target_size=(96,96))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")   # convert the data and labels to NumPy arrays\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(data[88],cmap=\"gray\")\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()  # perform one-hot encoding on the labels\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 96, 96, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML MODEL - USING MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseModel = MobileNetV2(input_shape=(96,96,3),alpha=0.35,weights=\"imagenet\",include_top=False,input_tensor=Input(shape=(96, 96, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D()(headModel)\n",
    "headModel = Flatten(input_shape=(128,128))(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPILING MAIN MODEL...\n",
      "Epoch 1/30\n",
      "19/19 [==============================] - 7s 159ms/step - loss: 0.6463 - accuracy: 0.6718 - val_loss: 0.4983 - val_accuracy: 0.7812\n",
      "Epoch 2/30\n",
      "19/19 [==============================] - 2s 104ms/step - loss: 0.4375 - accuracy: 0.8335 - val_loss: 0.4230 - val_accuracy: 0.8500\n",
      "Epoch 3/30\n",
      "19/19 [==============================] - 2s 116ms/step - loss: 0.3823 - accuracy: 0.8735 - val_loss: 0.3790 - val_accuracy: 0.8438\n",
      "Epoch 4/30\n",
      "19/19 [==============================] - 3s 149ms/step - loss: 0.3554 - accuracy: 0.8760 - val_loss: 0.3509 - val_accuracy: 0.8500\n",
      "Epoch 5/30\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.2935 - accuracy: 0.9182 - val_loss: 0.3405 - val_accuracy: 0.8562\n",
      "Epoch 6/30\n",
      "19/19 [==============================] - 3s 140ms/step - loss: 0.2995 - accuracy: 0.8930 - val_loss: 0.3207 - val_accuracy: 0.8875\n",
      "Epoch 7/30\n",
      "19/19 [==============================] - 3s 151ms/step - loss: 0.2498 - accuracy: 0.9356 - val_loss: 0.3102 - val_accuracy: 0.8875\n",
      "Epoch 8/30\n",
      "19/19 [==============================] - 3s 141ms/step - loss: 0.2484 - accuracy: 0.9129 - val_loss: 0.3080 - val_accuracy: 0.8687\n",
      "Epoch 9/30\n",
      "19/19 [==============================] - 2s 131ms/step - loss: 0.2292 - accuracy: 0.9182 - val_loss: 0.2995 - val_accuracy: 0.8750\n",
      "Epoch 10/30\n",
      "19/19 [==============================] - 3s 135ms/step - loss: 0.2195 - accuracy: 0.9238 - val_loss: 0.2964 - val_accuracy: 0.8687\n",
      "Epoch 11/30\n",
      "19/19 [==============================] - 3s 139ms/step - loss: 0.2196 - accuracy: 0.9381 - val_loss: 0.2880 - val_accuracy: 0.8813\n",
      "Epoch 12/30\n",
      "19/19 [==============================] - 3s 133ms/step - loss: 0.1997 - accuracy: 0.9470 - val_loss: 0.2979 - val_accuracy: 0.8750\n",
      "Epoch 13/30\n",
      "19/19 [==============================] - 3s 158ms/step - loss: 0.1848 - accuracy: 0.9501 - val_loss: 0.2848 - val_accuracy: 0.8813\n",
      "Epoch 14/30\n",
      "19/19 [==============================] - 3s 150ms/step - loss: 0.1942 - accuracy: 0.9451 - val_loss: 0.2839 - val_accuracy: 0.8813\n",
      "Epoch 15/30\n",
      "19/19 [==============================] - 3s 146ms/step - loss: 0.1961 - accuracy: 0.9289 - val_loss: 0.2809 - val_accuracy: 0.8875\n",
      "Epoch 16/30\n",
      "19/19 [==============================] - 3s 136ms/step - loss: 0.1695 - accuracy: 0.9334 - val_loss: 0.2847 - val_accuracy: 0.8813\n",
      "Epoch 17/30\n",
      "19/19 [==============================] - 3s 137ms/step - loss: 0.1605 - accuracy: 0.9578 - val_loss: 0.2779 - val_accuracy: 0.8938\n",
      "Epoch 18/30\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.1555 - accuracy: 0.9723 - val_loss: 0.2828 - val_accuracy: 0.8813\n",
      "Epoch 19/30\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.1665 - accuracy: 0.9500 - val_loss: 0.2775 - val_accuracy: 0.9000\n",
      "Epoch 20/30\n",
      "19/19 [==============================] - 3s 138ms/step - loss: 0.1530 - accuracy: 0.9503 - val_loss: 0.2901 - val_accuracy: 0.8750\n",
      "Epoch 21/30\n",
      "19/19 [==============================] - 3s 138ms/step - loss: 0.1574 - accuracy: 0.9503 - val_loss: 0.2858 - val_accuracy: 0.8875\n",
      "Epoch 22/30\n",
      "19/19 [==============================] - 3s 135ms/step - loss: 0.1404 - accuracy: 0.9757 - val_loss: 0.2791 - val_accuracy: 0.8938\n",
      "Epoch 23/30\n",
      "19/19 [==============================] - 3s 136ms/step - loss: 0.1392 - accuracy: 0.9697 - val_loss: 0.2759 - val_accuracy: 0.8813\n",
      "Epoch 24/30\n",
      "19/19 [==============================] - 3s 134ms/step - loss: 0.1358 - accuracy: 0.9737 - val_loss: 0.2827 - val_accuracy: 0.8875\n",
      "Epoch 25/30\n",
      "19/19 [==============================] - 3s 147ms/step - loss: 0.1391 - accuracy: 0.9723 - val_loss: 0.2764 - val_accuracy: 0.8938\n",
      "Epoch 26/30\n",
      "19/19 [==============================] - 3s 144ms/step - loss: 0.1206 - accuracy: 0.9774 - val_loss: 0.2756 - val_accuracy: 0.8938\n",
      "Epoch 27/30\n",
      "19/19 [==============================] - 3s 136ms/step - loss: 0.1082 - accuracy: 0.9742 - val_loss: 0.2760 - val_accuracy: 0.8938\n",
      "Epoch 28/30\n",
      "19/19 [==============================] - 3s 137ms/step - loss: 0.1120 - accuracy: 0.9740 - val_loss: 0.2902 - val_accuracy: 0.8750\n",
      "Epoch 29/30\n",
      "19/19 [==============================] - 3s 136ms/step - loss: 0.1085 - accuracy: 0.9771 - val_loss: 0.2807 - val_accuracy: 0.8938\n",
      "Epoch 30/30\n",
      "19/19 [==============================] - 3s 138ms/step - loss: 0.1104 - accuracy: 0.9805 - val_loss: 0.2753 - val_accuracy: 0.8938\n"
     ]
    }
   ],
   "source": [
    "print(\"COMPILING MAIN MODEL...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "H = model.fit(trainX, trainY, steps_per_epoch=len(trainX) // BS, \n",
    "          validation_data=(testX, testY), validation_steps=len(testX) // BS, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATING NETWORK...\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUATING NETWORK...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.88      0.91      0.90        80\n",
      "without_mask       0.91      0.88      0.89        80\n",
      "\n",
      "    accuracy                           0.89       160\n",
      "   macro avg       0.89      0.89      0.89       160\n",
      "weighted avg       0.89      0.89      0.89       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIdxs, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING MASK DETECTION MODEL...\n"
     ]
    }
   ],
   "source": [
    "print(\"SAVING MASK DETECTION MODEL...\")\n",
    "model.save(r'C:\\Users\\shubh\\anaconda3\\envs\\PROJECT\\FACEMASK DETECTION\\model.h5',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERAS_MODEL_NAME=\"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 2.048 Megabytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(r'C:\\Users\\shubh\\anaconda3\\envs\\PROJECT\\FACEMASK DETECTION\\model.h5'),\"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSORFLOW LITE CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shubh\\AppData\\Local\\Temp\\tmpnfjm0ok6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\shubh\\AppData\\Local\\Temp\\tmpnfjm0ok6\\assets\n"
     ]
    }
   ],
   "source": [
    "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tf_lite_converter.optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "#tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = tf_lite_converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597904"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
    "open(tflite_model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 583.891 kilobytes\n"
     ]
    }
   ],
   "source": [
    "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACEMASK DETECTION VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "    # grab the dimensions of the frame and then construct a blob from it\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),(104.0, 177.0, 123.0))\n",
    "\n",
    "    # pass the blob through the network and obtain the face detections\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "\n",
    "    # initialize our list of faces, their corresponding locations, and the list of predictions from our face mask network\n",
    "    faces = []\n",
    "    locs = []\n",
    "    preds = []\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the detection\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter out weak detections by ensuring the confidence is greater than the minimum confidence\n",
    "        if confidence > args[\"confidence\"]:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # ensure the bounding boxes fall within the dimensions of the frame\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "            # extract the face ROI, convert it from BGR to RGB channel ordering, resize it to 224x224, and preprocess it\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "\n",
    "            # add the face and bounding boxes to their respective lists\n",
    "            faces.append(face)\n",
    "            locs.append((startX, startY, endX, endY))\n",
    "\n",
    "    # only make a predictions if at least one face was detected\n",
    "    if len(faces) > 0:\n",
    "        # for faster inference we'll make batch predictions on *all* faces at the same time rather than one-by-one predictions in the above `for` loop\n",
    "        faces = np.array(faces, dtype=\"float32\")\n",
    "        preds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "    # return a 2-tuple of the face locations and their corresponding locations\n",
    "    return (locs, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-f\", \"--face\", type=str,\n",
    "    default=\"face_detector\",\n",
    "    help=\"path to face detector model directory\")\n",
    "ap.add_argument(\"-m\", \"--model\", type=str,\n",
    "    default=\"mask_detector.model\",\n",
    "    help=\"path to trained face mask detector model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "    help=\"minimum probability to filter weak detections\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our serialized face detector model from disk\n",
    "print(\"[INFO] loading face detector model...\")\n",
    "prototxtPath = os.path.sep.join([args[\"face\"], \"deploy.prototxt\"])\n",
    "weightsPath = os.path.sep.join([args[\"face\"],\n",
    "    \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the face mask detector model from disk\n",
    "print(\"[INFO] loading face mask detector model...\")\n",
    "maskNet = load_model(args[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the video stream and allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    # detect faces in the frame and determine if they are wearing a face mask or not\n",
    "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "    # loop over the detected face locations and their corresponding locations\n",
    "    for (box, pred) in zip(locs, preds):\n",
    "        # unpack the bounding box and predictions\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "\n",
    "        # determine the class label and color we'll use to draw the bounding box and text\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "        if label == \"No Mask\":\n",
    "            notification.notify(\n",
    "                title = \"***No Mask Detected***\",\n",
    "                        message = \"Wear Mask to stay safe! \",\n",
    "                        app_icon = \"images/1.ico\",    #ico file should be downloaded\n",
    "                        timeout = 1\n",
    "                    )\n",
    "\n",
    "\n",
    "        # include the probability in the label\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "        # display the label and bounding box rectangle on the output frame\n",
    "        cv2.putText(frame, label, (startX, startY - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "        # Alarm when \"No Mask\" detected\n",
    "        if mask < withoutMask:\n",
    "            path = os.path.abspath(\"Alarm.wav\")\n",
    "            playsound(path)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
